{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a90309d-4753-4a72-af2c-28c0e4d112ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce21291d-ff76-44d8-83ef-ba164cc67bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/'.join(os.getcwd().split('/')[:-1])+'/params.json','r') as params:\n",
    "    params = json.load(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ddb0421-84c5-40de-818c-7b669bf5e2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "s3_client = boto3.client('s3')\n",
    "sm_role = params['sm_role']\n",
    "lambda_role = params['lambda_role']\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess, default_bucket=params['bucket_pipeline'])\n",
    "bucket = params['bucket_pipeline'] # sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "model_package_group_name = 'nba-models-2023' # model name in model registry\n",
    "pipeline_name = 'nba-pipeline-1'  # sageMaker Pipeline name\n",
    "prefix = 'nba'\n",
    "\n",
    "# must reset this time every time we want a pipeline\n",
    "current_time = time.strftime('%m-%d-%H-%M-%S', time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5023e10d-22b9-49f8-b7c8-69b34d99d765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0078f3ff-24e4-4568-8909-78a968a503d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_s3 = f's3://{bucket}/{prefix}/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17dcf2a2-be7b-400d-bd4d-84388637e178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "\n",
    "# raw input data\n",
    "input_data = ParameterString(name='InputData', default_value=raw_s3)\n",
    "\n",
    "# training step parameters\n",
    "training_epochs = ParameterString(name='TrainingEpochs', default_value='10')\n",
    "\n",
    "# model performance step parameters\n",
    "accuracy_threshold = ParameterFloat(name='AccuracyThreshold', default_value=0.6)\n",
    "\n",
    "# inference step parameters\n",
    "endpoint_instance_type = ParameterString(name='EndpointInstanceType', default_value='ml.m5.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "636e3f80-8b3d-4939-9d06-a6bd7a98746b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_version = '2.9.2'\n",
    "sk_version = '1.0-1'\n",
    "python_version = 'py39'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e44bb6b-b3b7-4d39-8fc6-6b79d3178a6a",
   "metadata": {},
   "source": [
    "#### **HELPERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f683dee-01a4-416d-8123-4f251fb2a18f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_s3(file_path, myfile, bucket=params['bucket_data'], dedupe_cols=None, sort=None, ascending=True, compression='zip'):\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    if type(myfile) == pd.core.frame.DataFrame:\n",
    "        if sort is not None:\n",
    "            myfile = myfile.sort_values(by=sort, ascending=ascending)\n",
    "        if dedupe_cols is not None:\n",
    "            myfile = myfile.drop_duplicates(subset=dedupe_cols, keep='first')\n",
    "        output_buffer = BytesIO() if compression == 'zip' else StringIO()\n",
    "        if compression == 'zip': file_path = '.'.join(file_path.split('.')[:-1])+'.zip'\n",
    "        myfile.to_csv(output_buffer, index=False, compression={'method':compression, 'archive_name':file_name})\n",
    "        myfile = output_buffer\n",
    "    s3_resource.Object(bucket, file_path).put(Body=myfile.getvalue())    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686fa7d-db04-43e9-acb2-e6aab0317dca",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **PREPROCESS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1b540b4-12a1-43fb-970f-bc66e996b6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocess.py\n",
    "import os, re\n",
    "import glob\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "\n",
    "from collections import Counter, deque, defaultdict\n",
    "import datetime\n",
    "from datetime import timedelta as td\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import sys\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = 'sagemaker-pipelines-hwm'\n",
    "\n",
    "input_path = '/opt/ml/processing/input'\n",
    "train_path = '/opt/ml/processing/train'\n",
    "val_path = '/opt/ml/processing/val'\n",
    "test_path = '/opt/ml/processing/test'\n",
    "\n",
    "def read_s3(file_path, bucket='hwm-nba', output=None, columns=None):\n",
    "    data = s3_resource.Object(bucket, file_path).get()['Body'].read()\n",
    "    if file_path[-3:] == 'zip':\n",
    "        data = zipfile.ZipFile(BytesIO(data))\n",
    "        data = data.read(data.namelist()[0])\n",
    "    data = data.decode('utf-8')\n",
    "    if output == 'dataframe':\n",
    "        kwargs = {'header': 0}\n",
    "        if columns is not None: kwargs['names'] = columns\n",
    "        data = pd.read_csv(StringIO(data), **kwargs)\n",
    "    return data\n",
    "\n",
    "\n",
    "def basic_features(games):\n",
    "    filters = []\n",
    "    filters.append(\"away != 'No Games'\")\n",
    "    filters.append(\"away != '0'\")\n",
    "    filters.append(\"hs >= 50\")\n",
    "    filters.append(\"hs != '-'\")\n",
    "    filters.append(\"diff != 0\")\n",
    "    filters.append(\"date >= '1996'\")\n",
    "\n",
    "    # games.columns = [re.sub(' ','_',c.lower()) for c in list(games.columns)]\n",
    "    games = games.drop_duplicates(subset=['detail_path'], keep='last')\n",
    "    \n",
    "    games.loc[:,'hs'] = games.loc[:,'hs'].apply(lambda x: make_int(x))\n",
    "    games.loc[:,'as'] = games.loc[:,'as'].apply(lambda x: make_int(x))\n",
    "\n",
    "    # clean up home and away scores\n",
    "    games['ot'] = games.apply(lambda x: 0 if (x['ot']=='N' or x['away']=='No Games') \\\n",
    "                              else (1 if int(max(x['as'],x['hs']))<200 else int(str(max(x['as'],x['hs']))[:1])),axis=1)\n",
    "\n",
    "    games['as'] = games.apply(lambda x: x['as'] if (x['ot']<2 or x['as']<200) else x['as'] % 1000, axis=1)\n",
    "    games['hs'] = games.apply(lambda x: x['hs'] if (x['ot']<2 or x['hs']<200) else x['hs'] % 1000, axis=1)\n",
    "\n",
    "    games['game_subtype'] = games['game_type'].apply(lambda x: re.sub('^(east|west)-', '', re.sub('-[0-9]{1}$','',x)))\n",
    "    games['game_type'] = games['game_type'].apply(lambda x: x if x in ['preseason','regular'] else 'playoffs')\n",
    "\n",
    "    games['diff'] = games.apply(lambda r: np.abs(r['hs']-r['as']),axis=1)\n",
    "    games = games.query(' & '.join(filters)).reset_index(drop=True)\n",
    "    \n",
    "    # clean the team names - reconcile old franchises with new, and aggregate the long tail of guest/novelty teams\n",
    "    games['home'] = games['home'].apply(lambda x: team_names_dict[x])\n",
    "    games['away'] = games['away'].apply(lambda x: team_names_dict[x])\n",
    "        \n",
    "    games['month'] = games['date'].apply(lambda x: x[5:7])\n",
    "    games['date'] = games['date'].apply(lambda x: dt.strptime(x,'%Y-%m-%d').date())\n",
    "    games['winner'] = games.apply(lambda x: x['home'] if x['hs'] >= x['as'] else x['away'], axis=1)\n",
    "    games['home_win'] = games.apply(lambda x: 1 if x['hs'] >= x['as'] else 0, axis=1)\n",
    "    games['season'] = games['date'].apply(lambda x: str((x-td(days=225)).year)+'-'+str((x-td(days=225)).year+1)) # mid-august split\n",
    "    # exceptions\n",
    "    games['season'] = games.apply(lambda x: '2019-2020' if (dt.strftime(x['date'],'%Y-%m-%d')>='2020-03-01' \\\n",
    "                                                            and dt.strftime(x['date'],'%Y-%m-%d')<='2020-11-15') else x['season'], axis=1)\n",
    "\n",
    "    games['is_preseason'] = games.apply(lambda x: 1 if x['game_type']=='preseason' else 0,axis=1)\n",
    "    games['is_playoffs'] = games.apply(lambda x: 0 if x['game_type'] in ['preseason','regular'] else 1,axis=1)\n",
    "    \n",
    "    games['team_pair'] = games.apply(lambda r: [r['away'], r['home']], axis=1)\n",
    "    games['team_pair'].apply(lambda r: r.sort())\n",
    "    games['team_pair'] = games['team_pair'].apply(lambda r: '-'.join(r))\n",
    "    \n",
    "    del games['detail_data']\n",
    "    del games['rand']\n",
    "    \n",
    "    return games\n",
    "\n",
    "\n",
    "def playoff_features(games): # etl the playoff calculations\n",
    "    games.columns = [re.sub(' ','_',c.lower()) for c in list(games.columns)]\n",
    "    playoff_games = games[games['game_type']=='playoffs'].iloc[:,:].sort_values(by=['season', 'team_pair', 'date']).reset_index(drop=True)\n",
    "\n",
    "    playoff_games['winner_1'] = playoff_games.apply(lambda r: 1 if r['winner']==r['team_pair'][:3] else 0, axis=1)\n",
    "    playoff_games['winner_2'] = playoff_games.apply(lambda r: 1 if r['winner']==r['team_pair'][-3:] else 0, axis=1)\n",
    "\n",
    "    playoff_games[['t1_wins_after_game', 't2_wins_after_game']] = \\\n",
    "        playoff_games[['season', 'team_pair', 'winner_1', 'winner_2']].groupby(['season', 'team_pair'])[['winner_1', 'winner_2']].transform(pd.Series.cumsum)\n",
    "    del playoff_games['winner_1']\n",
    "    del playoff_games['winner_2']\n",
    "\n",
    "    playoff_games['leader_after_game'] = playoff_games.apply(lambda r: r['team_pair'][:3] if r['t1_wins_after_game']>r['t2_wins_after_game'] \\\n",
    "                                                             else (r['team_pair'][-3:] if r['t2_wins_after_game']>r['t1_wins_after_game'] \\\n",
    "                                                                   else 'tied series'), axis=1)\n",
    "    playoff_games[['season2', 'team_pair2', 't1_wins_before_game', 't2_wins_before_game', \n",
    "                   'leader_before_game']] = playoff_games[['season', 'team_pair', 't1_wins_after_game',\n",
    "                                                           't2_wins_after_game', 'leader_after_game']].shift(periods=1)\n",
    "    \n",
    "    playoff_games['t1_wins_before_game'] = playoff_games.apply(lambda r: 0 if np.isnan(r['t1_wins_before_game']) \\\n",
    "                                                               or r['season']!=r['season2'] else int(r['t1_wins_before_game']), axis=1)\n",
    "    playoff_games['t2_wins_before_game'] = playoff_games.apply(lambda r: 0 if np.isnan(r['t2_wins_before_game']) \\\n",
    "                                                               or r['season']!=r['season2'] else int(r['t2_wins_before_game']), axis=1)\n",
    "    playoff_games['leader_before_game'] = playoff_games.apply(lambda r: 'series starting' \\\n",
    "                                                              if str(r['leader_before_game'])=='nan' or r['season']!=r['season2'] \\\n",
    "                                                              else r['leader_before_game'], axis=1)\n",
    "    del playoff_games['season2']\n",
    "    del playoff_games['team_pair2']\n",
    "    \n",
    "    playoff_series_winners = playoff_games.drop_duplicates(subset=['season', 'team_pair'],keep='last').reset_index(drop=True)\n",
    "    playoff_series_winners = playoff_series_winners[['date', 'season', 'game_type', 'team_pair', 'winner']]\n",
    "    playoff_series_winners = playoff_series_winners.sort_values(by=['winner', 'date']).reset_index(drop=True)\n",
    "    playoff_series_winners['count'] = 1\n",
    "\n",
    "    playoff_series_winners['playoff_round'] = playoff_series_winners[['winner', 'season', 'game_type',\n",
    "                                                                      'count']].groupby(['winner', 'season', 'game_type'])['count'].transform(pd.Series.cumsum)\n",
    "    del playoff_series_winners['count']\n",
    "\n",
    "    playoff_series_winners = playoff_series_winners[['winner', 'season', 'game_type', 'team_pair', 'playoff_round']]\n",
    "    playoff_series_winners.columns = ['series_winner', 'season', 'game_type', 'team_pair', 'playoff_round']\n",
    "\n",
    "    playoff_games = playoff_games.merge(playoff_series_winners, how='left', on=['season', 'team_pair', 'game_type'], sort=False)\n",
    "    \n",
    "    playoff_games['knockout_game'] = playoff_games.apply(lambda r: 1 if max(r['t1_wins_before_game'], r['t2_wins_before_game'])==3 \\\n",
    "                                                         else (1 if max(r['t1_wins_before_game'], r['t2_wins_before_game'])==2 and \\\n",
    "                                                               r['playoff_round']==1 and r['season'] < '2002' else 0), axis=1)\n",
    "    \n",
    "    playoff_games = playoff_games[['date', 'detail_path', 't1_wins_after_game', 't2_wins_after_game', 'leader_after_game', 't1_wins_before_game',\n",
    "                                   't2_wins_before_game', 'leader_before_game', 'series_winner', 'playoff_round', 'knockout_game']]\n",
    "    \n",
    "    games = games.merge(playoff_games, how='left', on=['date', 'detail_path'], sort=False)\n",
    "    \n",
    "    games['game_subtype'] = games['playoff_round'].apply(lambda x: 0 if np.isnan(x) else int(x))\n",
    "    del games['playoff_round']\n",
    "\n",
    "    return games\n",
    "\n",
    "\n",
    "def wins_n_games(games):\n",
    "    teams_unique = list(set(get_team_names(games, output='df')['team']))+['Other']\n",
    "    sequences = [3, 5, 10, 20, 50, 100]\n",
    "    for j, team in enumerate(teams_unique):\n",
    "        temp = games[games['team_pair'].str.contains(team)][['detail_path','home','away','team_pair','winner']]\n",
    "        temp_home = games[games['home'].str.contains(team)][['detail_path','home','winner']]\n",
    "        temp_away = games[games['away'].str.contains(team)][['detail_path','away','winner']]\n",
    "        \n",
    "        wins = np.array(np.where(temp['winner']==team, 1, 0))\n",
    "        wins_home = np.array(np.where(temp_home['winner']==team, 1, 0))\n",
    "        wins_away = np.array(np.where(temp_away['winner']==team, 1, 0))\n",
    "        \n",
    "        # streak test\n",
    "        streak = [0,wins[0]]\n",
    "        for i in range(1, len(wins)-1):\n",
    "            next_val = streak[-1]+1 if wins[i]==1 else 0\n",
    "            streak.append(next_val)\n",
    "        temp['streak'] = np.asarray(streak)\n",
    "        temp['streak_home'] = np.where(temp['home']==team, temp['streak'], -1)\n",
    "        temp['streak_away'] = np.where(temp['away']==team, temp['streak'], -1)\n",
    "\n",
    "        # streak home test\n",
    "        streak_home = [0,wins_home[0]]\n",
    "        for i in range(1, len(wins_home)-1):\n",
    "            next_val = streak_home[-1]+1 if wins_home[i]==1 else 0\n",
    "            streak_home.append(next_val)\n",
    "        temp_home['streak_home_home'] = np.asarray(streak_home)\n",
    "        \n",
    "        # streak away test\n",
    "        streak_away = [0,wins_away[0]]\n",
    "        for i in range(1, len(wins_away)-1):\n",
    "            next_val = streak_away[-1]+1 if wins_away[i]==1 else 0\n",
    "            streak_away.append(next_val)\n",
    "        temp_away['streak_away_away'] = np.asarray(streak_away)\n",
    "        \n",
    "        temp = temp.merge(temp_home[['detail_path','streak_home_home']], how='left', on='detail_path', sort=False)\n",
    "        temp = temp.merge(temp_away[['detail_path','streak_away_away']], how='left', on='detail_path', sort=False)\n",
    "        \n",
    "        for s in sequences:\n",
    "            temp['wins'+str(s)] = np.asarray([sum(wins[max(0,i-s):i]) for i in range(len(wins))])\n",
    "            temp['wins'+str(s)+'_home'] = np.where(temp['home']==team, temp['wins'+str(s)], -1)\n",
    "            temp['wins'+str(s)+'_away'] = np.where(temp['away']==team, temp['wins'+str(s)], -1)\n",
    "        wins_df = temp if j==0 else pd.concat([wins_df, temp], axis=0)\n",
    "\n",
    "        # return wins_df\n",
    "    \n",
    "    wins_df = wins_df[~wins_df['team_pair'].str.contains('Other')]\n",
    "\n",
    "    home_streaks = wins_df[wins_df['streak_home']>-1].sort_index()\n",
    "    away_streaks = wins_df[wins_df['streak_away']>-1].sort_index()\n",
    "\n",
    "    home_wins = wins_df[wins_df['wins3_home']>-1].sort_index()\n",
    "    away_wins = wins_df[wins_df['wins3_away']>-1].sort_index()\n",
    "    \n",
    "    wins_df = home_wins[['detail_path']]\n",
    "    wins_df = wins_df.merge(home_streaks[['detail_path', 'streak_home', 'streak_home_home']], how='left', on='detail_path', sort=False)\n",
    "    wins_df = wins_df.merge(away_streaks[['detail_path', 'streak_away', 'streak_away_away']], how='left', on='detail_path', sort=False)\n",
    "    wins_df = wins_df.merge(home_wins[['detail_path']+['wins'+str(s)+'_home' for s in sequences]], how='left', on='detail_path', sort=False)\n",
    "    wins_df = wins_df.merge(away_wins[['detail_path']+['wins'+str(s)+'_away' for s in sequences]], how='left', on='detail_path', sort=False)\n",
    "    for col in list(wins_df.columns)[1:]:\n",
    "        wins_df[col] = wins_df[col].fillna(0).astype(int)\n",
    "\n",
    "    games = games.merge(wins_df, how='inner', on=['detail_path'], sort=-False).reset_index(drop=True)\n",
    "    return games\n",
    "\n",
    "\n",
    "def opponents(games):\n",
    "    games['team_pair_sorted'] = np.asarray([g[:3]+'-'+g[-3:] if g[:3]<=g[-3:] else g[-3:]+'-'+g[:3] for g in games['team_pair']])\n",
    "    unique_pairs = np.unique(games['team_pair_sorted'])\n",
    "\n",
    "    for j, teams in enumerate(unique_pairs):\n",
    "        temp = games[games['team_pair_sorted']==teams][['detail_path','team_pair_sorted','winner']]\n",
    "        wins = np.array(np.where(temp['winner']==teams[:3], 1, 0))\n",
    "\n",
    "        streak1, streak2 = [0], [0]\n",
    "        for i in range(len(wins)-1):\n",
    "            next_val1 = streak1[-1]+1 if wins[i]==1 else 0\n",
    "            streak1.append(next_val1)\n",
    "            next_val2 = streak2[-1]+1 if wins[i]==0 else 0\n",
    "            streak2.append(next_val2)\n",
    "        temp['streak1'] = np.asarray(streak1)\n",
    "        temp['streak2'] = np.asarray(streak2)\n",
    "\n",
    "        opponents_df = temp if j==0 else pd.concat([opponents_df, temp], axis=0)\n",
    "\n",
    "    games = games.merge(opponents_df[['detail_path','team_pair_sorted','streak1','streak2']],\n",
    "                        how='left', on=['detail_path', 'team_pair_sorted'], sort=False)\n",
    "    games['streak_opponents_home'] = games.apply(lambda r: r['streak1'] if r['home'] == r['team_pair_sorted'][:3] else r['streak2'], axis=1)\n",
    "    games['streak_opponents_away'] = games.apply(lambda r: r['streak1'] if r['away'] == r['team_pair_sorted'][:3] else r['streak2'], axis=1)\n",
    "\n",
    "    del games['streak1']\n",
    "    del games['streak2']\n",
    "\n",
    "    return games\n",
    "\n",
    "\n",
    "def last_n_days(games):\n",
    "    teams_unique = list(set(get_team_names(games, output='df')['team'])) # +['Other']\n",
    "    sequences = [2, 3, 5, 10, 20]\n",
    "\n",
    "    min_date = min(games['date'])\n",
    "    max_date = max(games['date'])\n",
    "    dates = [min_date + datetime.timedelta(days=d) for d in range((max_date - min_date).days)]\n",
    "\n",
    "    for j, team in enumerate(teams_unique):\n",
    "        temp = games[games['team_pair'].str.contains(team)][['date','detail_path','home','away']]\n",
    "        d = np.array(temp['date'])\n",
    "        temp['days_last_played'] = [0]+[(d[i]-d[i-1]).days for i in range(1,len(d))]\n",
    "\n",
    "        y_dates = np.array(temp['date'])\n",
    "        y_df = pd.DataFrame(y_dates,columns=['date'])\n",
    "        y_df['game'] = 1\n",
    "        n_dates = list(set(dates) - set(y_dates))\n",
    "        n_df = pd.DataFrame(n_dates,columns=['date'])\n",
    "        n_df['game'] = 0\n",
    "        df = pd.concat([y_df, n_df], axis=0).sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "        for s in sequences:\n",
    "            game_seq = np.array(df['game'])\n",
    "            cum_games = np.asarray([0]+[sum(game_seq[max(0,i-s):i]) for i in range(1,len(game_seq))])\n",
    "            df['cum_games_'+str(s)] = cum_games\n",
    "\n",
    "        temp_home = temp[temp['home']==team]\n",
    "        temp_home = temp_home.merge(df, how='inner', on=['date'], sort=False)\n",
    "        temp_home_all = temp_home if j==0 else pd.concat([temp_home_all, temp_home], axis=0)\n",
    "\n",
    "        temp_away = temp[temp['away']==team]\n",
    "        temp_away = temp_away.merge(df, how='inner', on=['date'], sort=False)\n",
    "        temp_away_all = temp_away if j==0 else pd.concat([temp_away_all, temp_away], axis=0)\n",
    "\n",
    "    temp_home_all = temp_home_all[['date','detail_path']+['cum_games_'+str(s) for s in sequences]+['days_last_played']]\n",
    "    temp_home_all.columns = ['date','detail_path']+[c+'_home' for c in list(temp_home_all.columns)[2:]]\n",
    "\n",
    "    temp_away_all = temp_away_all[['date','detail_path']+['cum_games_'+str(s) for s in sequences]+['days_last_played']]\n",
    "    temp_away_all.columns = ['date','detail_path']+[c+'_away' for c in list(temp_away_all.columns)[2:]]        \n",
    "\n",
    "    games = games.merge(temp_home_all, how='left', on=['date','detail_path'], sort=False)\n",
    "    games = games.merge(temp_away_all, how='left', on=['date','detail_path'], sort=False)\n",
    "\n",
    "    return games\n",
    "\n",
    "\n",
    "def generate_standings(table, date, conf=None):\n",
    "    if type(date) == str:\n",
    "        date = datetime.datetime.strptime(date,'%Y-%m-%d').date()\n",
    "    if type(table['date'][0]) == str:\n",
    "        table['date'] = table['date'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').date())\n",
    "\n",
    "    season = max(table[table['date']<date]['season'])\n",
    "    games_season = table[(table['season']==season) & (table['date']<date)]\n",
    "    games_season.loc[:,'count'] = 1\n",
    "    games_preseason = games_season[games_season['game_type']=='preseason'].reset_index(drop=True)\n",
    "    games_regular = games_season[games_season['game_type']=='regular'].reset_index(drop=True)\n",
    "    games_playoffs = games_season[games_season['game_type']=='playoffs'].reset_index(drop=True)\n",
    "\n",
    "    hw = games_regular[games_regular['home']==games_regular['winner']][['home','count','hs']].groupby('home').sum()\n",
    "    hl = games_regular[games_regular['home']!=games_regular['winner']][['home','count']].groupby('home').sum()\n",
    "    aw = games_regular[games_regular['away']==games_regular['winner']][['away','count','as']].groupby('away').sum()\n",
    "    al = games_regular[games_regular['away']!=games_regular['winner']][['away','count']].groupby('away').sum()\n",
    "\n",
    "    final_table = pd.concat([hw, hl, aw, al], axis=1).reset_index().fillna(0)\n",
    "\n",
    "    final_table.columns = ['team', 'wins_home', 'points_home', 'losses_home', 'wins_away', 'points_away', 'losses_away']\n",
    "\n",
    "    final_table['wins'] = final_table['wins_home']+final_table['wins_away']\n",
    "    final_table['losses'] = final_table['losses_home']+final_table['losses_away']\n",
    "    final_table['played'] = final_table['wins']+final_table['losses']\n",
    "    final_table['diff'] = final_table['wins'] - final_table['losses']\n",
    "    final_table['conf'] = final_table['team'].map(get_conference)\n",
    "\n",
    "    final_table = final_table[['team', 'conf', 'played', 'wins', 'losses', 'wins_home', 'losses_home',\n",
    "                               'points_home', 'wins_away', 'losses_away', 'points_away', 'diff']]\n",
    "    final_table = final_table.sort_values(by=['diff', 'played'],ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    if conf is not None:\n",
    "        final_table = final_table[final_table['conf']==conf].reset_index(drop=True)\n",
    "\n",
    "    final_table = final_table.reset_index()\n",
    "    final_table.columns = ['pos']+list(final_table.columns)[1:]\n",
    "    final_table['pos'] += 1\n",
    "\n",
    "    return final_table\n",
    "\n",
    "\n",
    "def build_standings(games):\n",
    "    for i, d in enumerate(set(games['date'])):\n",
    "        if i%500==0: print(i)\n",
    "        try:\n",
    "            standings = generate_standings(games, d)\n",
    "            standings['date'] = d\n",
    "            if i == 0:\n",
    "                standings_all = standings\n",
    "            else:\n",
    "                standings_all = pd.concat([standings_all, standings], axis=0)\n",
    "        except:\n",
    "            # print(d)\n",
    "            pass\n",
    "    standings_all = standings_all.sort_values(by=['date', 'pos'], ascending=[True, True])\n",
    "    standings_all.to_csv('../data/processed/standings.csv', index=False)\n",
    "    return standings_all\n",
    "\n",
    "\n",
    "def standings(games, standing_path=input_path+'/standings.zip'):\n",
    "    standing = read_csv_from_zip(standing_path) # build_standings(games)\n",
    "    try:\n",
    "        standing['date'] = standing['date'].apply(lambda x: dt.strptime(x,'%Y-%m-%d').date())\n",
    "    except:\n",
    "        pass\n",
    "    standings_home = standing[['team','date','wins','losses','wins_home','losses_home','points_home','wins_away','losses_away','points_away','diff']]\n",
    "    standings_home.columns = ['team','date']+['home_standing_'+c for c in list(standings_home.columns)[2:]]\n",
    "    standings_away = standing[['team','date','wins','losses','wins_home','losses_home','points_home','wins_away','losses_away','points_away','diff']]\n",
    "    standings_away.columns = ['team','date']+['away_standing_'+c for c in list(standings_away.columns)[2:]]\n",
    "\n",
    "    games = games.merge(standings_home, how='left', left_on=['home','date'], right_on=['team','date'], sort=False)\n",
    "    games = games.merge(standings_away, how='left', left_on=['away','date'], right_on=['team','date'], sort=False)\n",
    "\n",
    "    del games['team_x']\n",
    "    del games['team_y']\n",
    "\n",
    "    for c in list(games.columns)[-18:]:\n",
    "        games[c] = games[c].fillna(0)\n",
    "\n",
    "    games['standing_diff'] = games['home_standing_diff'] - games['away_standing_diff']\n",
    "    games['standing_points_diff'] = games['home_standing_points_home'] - games['away_standing_points_away']\n",
    "\n",
    "    return games\n",
    "\n",
    "\n",
    "def make_int(c):\n",
    "    try:\n",
    "        return int(c)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def day_diff(d1,d2,t):\n",
    "    try:\n",
    "        return int((d1-d2).days)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def delcols(df,c):\n",
    "    try:\n",
    "        del df[c]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "def datefill(d,end=None,numdays=0):\n",
    "    if end is None:\n",
    "        end = max(d) #.date()\n",
    "    dr = (end-min(d)).days #.date()\n",
    "    dl = [end - datetime.timedelta(days=x) for x in range(dr+1+numdays)]\n",
    "    # d = [d.date() for d in d]\n",
    "    date_list = [a for a in dl if a not in d]\n",
    "    if numdays > 0: return date_list[:numdays]\n",
    "    return date_list\n",
    "\n",
    "\n",
    "def get_counts_list(col, name, ascending=False, lim=None):\n",
    "    data = pd.DataFrame.from_dict([dict(Counter(col))]).T.sort_values(by=0, ascending=ascending).reset_index()\n",
    "    if lim is not None:\n",
    "        data = data[:lim]\n",
    "    data.columns = [name, 'count']\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_dupes(col):\n",
    "    df = pd.DataFrame.from_dict([dict(Counter(col))]).T.sort_values(by=0,ascending=False).reset_index()\n",
    "    dupes = df[df[0]>1]\n",
    "    if len(dupes)>0: return dupes\n",
    "    print('No Dupes')\n",
    "\n",
    "\n",
    "# team lookup to address the long-tail and reconcile franchises\n",
    "def get_team_names(games, output='dict', default='Other'):\n",
    "    team_replacements = {'NOH': 'NOP', 'NOK': 'NOP', 'SAN': 'SAS', 'GOS': 'GSW', 'UTH': 'UTA', 'PHL': 'PHI'}\n",
    "    active_teams = get_counts_list(games[games['away'] != 'No Games']['home'], 'team_raw', lim=40) # these are the valid teams\n",
    "    active_teams['team'] = active_teams['team_raw'].apply(lambda x: team_replacements[x] if x in team_replacements.keys() else x)\n",
    "    if output=='dict':\n",
    "        def def_value():\n",
    "            return default\n",
    "        team_dict = defaultdict(def_value)\n",
    "        for i in range(len(active_teams)):\n",
    "            team_dict[active_teams['team_raw'][i]] = active_teams['team'][i]\n",
    "        return team_dict\n",
    "    return active_teams[['team_raw', 'team']]\n",
    "\n",
    "\n",
    "def etl_process(data, tasks):\n",
    "    for t in tasks:\n",
    "        data = t(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_conference(team=None):\n",
    "    confs = {'East': ['BOS', 'MIL', 'PHI', 'CLE', 'BKN', 'MIA', 'NYK', 'ATL', 'WAS', 'CHI', 'TOR', 'IND', 'ORL', 'DET', 'CHA'],\n",
    "             'West': ['DEN', 'MEM', 'SAC', 'PHX', 'DAL', 'LAC', 'NOP', 'MIN', 'GSW', 'OKC', 'UTA', 'POR', 'LAL', 'SAS', 'HOU']}\n",
    "    if team is not None:\n",
    "        return 'East' if team in confs['East'] else 'West'\n",
    "    return confs\n",
    "\n",
    "\n",
    "def read_csv_from_zip(zip_path):\n",
    "    zip_file = ZipFile(zip_path)\n",
    "    file_name = zip_path.split('/')[-1].split('.')[0]+'.csv'\n",
    "    for z in zip_file.infolist():\n",
    "        if z.filename == file_name:\n",
    "            return pd.read_csv(zip_file.open(file_name))\n",
    "\n",
    "        \n",
    "def write_s3(file_path, myfile, bucket=bucket, dedupe_cols=None, sort=None, compression='zip'):\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    if type(myfile) == pd.core.frame.DataFrame:\n",
    "        if dedupe_cols is not None:\n",
    "            myfile = myfile.drop_duplicates(subset=dedupe_cols, keep='first')\n",
    "        if sort is not None:\n",
    "            myfile = myfile.sort_values(by=sort, ascending=True)\n",
    "        output_buffer = BytesIO() if compression == 'zip' else StringIO()\n",
    "        if compression == 'zip': file_path = '.'.join(file_path.split('.')[:-1])+'.zip'\n",
    "        myfile.to_csv(output_buffer, index=False, compression={'method':compression, 'archive_name':file_name})\n",
    "        myfile = output_buffer\n",
    "    s3_resource.Object(bucket, file_path).put(Body=myfile.getvalue())\n",
    "        \n",
    "\n",
    "def encode_features(col):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(col)\n",
    "    col = le.transform(col)\n",
    "    return col\n",
    "\n",
    "\n",
    "def standardize_features(col):\n",
    "    return (col-np.mean(col))/(np.std(col))\n",
    "\n",
    "\n",
    "def normalize_features(col):\n",
    "    return (col-min(col))/(max(col)-min(col))\n",
    "\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', package])\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    input_files = os.listdir(input_path)\n",
    "    \n",
    "    games = read_csv_from_zip(input_path + '/games.zip')\n",
    "    games.columns = [re.sub(' ','_',c.lower()) for c in list(games.columns)]\n",
    "    team_names_dict = get_team_names(games) \n",
    "    \n",
    "    max_played = np.max(np.unique(games[games['as'] != '-']['date']))\n",
    "    games = games[games['date'] <= max_played].reset_index(drop=True)\n",
    "    \n",
    "    games_final = etl_process(games, [basic_features, playoff_features, wins_n_games, opponents, last_n_days, standings])\n",
    "    \n",
    "    # making train and test, x and y\n",
    "    split = int(len(games)*0.8)\n",
    "    \n",
    "    target = 'home_win'\n",
    "    skip_cols = ['date', 'detail_path', 'team_pair', 'team_pair_sorted', 'winner', 'winner', 'hs', 'diff',\n",
    "                 'as', 'ot', 't1_wins_after_game', 't2_wins_after_game', 'leader_after_game', 'series_winner']\n",
    "    \n",
    "    col_map = {}\n",
    "    for c in games_final.columns:\n",
    "        if c not in skip_cols: col_map[c] = str(games_final[c].dtype)\n",
    "    \n",
    "    for c in col_map.keys():\n",
    "        if col_map[c] == 'object':\n",
    "            print('column:',c)\n",
    "            games_final[c] = games_final[c].astype(str)\n",
    "            games_final[c] = encode_features(games_final[c])\n",
    "        \n",
    "    games_final = games_final.fillna(0)\n",
    "    games_final = games_final[[c for c in games_final.columns if c not in skip_cols]]\n",
    "    games_final['standing_diff'] = np.where(games_final['standing_diff']<0, 0, np.where(games_final['standing_diff']<10, 1, 2))\n",
    "    \n",
    "    for i, c in enumerate(games_final.columns):\n",
    "        games_final[c] = standardize_features(games_final[c])\n",
    "        games_final[c] = normalize_features(games_final[c])\n",
    "    \n",
    "    test_frac = 0.1\n",
    "    train_frac = 1 - test_frac\n",
    "    \n",
    "    np.random.seed(56)\n",
    "    games_final_shuffled = games_final.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train = games_final_shuffled.iloc[:int(len(games_final)*train_frac),:]\n",
    "    test = games_final_shuffled.iloc[int(len(games_final)*train_frac):,:]\n",
    "    \n",
    "    train.to_csv(train_path+'/train.csv', index=False)\n",
    "    test.to_csv(test_path+'/test.csv', index=False)\n",
    "    \n",
    "    s3_client.upload_file(train_path+'/train.csv', bucket, 'nba/processed/train.csv')\n",
    "    s3_client.upload_file(test_path+'/test.csv', bucket, 'nba/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8577e21-fd72-4c23-ae93-2e6c2afb3000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from sagemaker.processing import FrameworkProcessor\n",
    "#from sagemaker.sklearn import SKLearn\n",
    "#from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "#from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "#from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "#sklearn_processor = FrameworkProcessor(\n",
    "#    estimator_cls=SKLearn,\n",
    "#    framework_version='0.23-1',\n",
    "#    instance_type='ml.m5.xlarge',\n",
    "#    instance_count=1,\n",
    "#    base_job_name=f'nba-preprocess',\n",
    "#    sagemaker_session=pipeline_session,\n",
    "#    role=role,\n",
    "#)\n",
    "\n",
    "# s3_input_meta = sagemaker.dataset_definition.inputs.S3Input(\n",
    "#     s3_uri='s3://sagemaker-pipelines-hwm/nba-pipeline-1/code/sourcedir.tar.gz'\n",
    "# )\n",
    "\n",
    "# processor_run_args = sklearn_processor.run(\n",
    "#     inputs=[\n",
    "#         ProcessingInput(input_name='input', source=input_data, destination='/opt/ml/processing/input'), #input_name='booba', s3_input=s3_input_meta, \n",
    "#     ],\n",
    "#     outputs=[\n",
    "#         ProcessingOutput(output_name='train', source='/opt/ml/processing/train'),\n",
    "#         ProcessingOutput(output_name='val', source='/opt/ml/processing/val'),\n",
    "#         ProcessingOutput(output_name='test', source='/opt/ml/processing/test'),\n",
    "#     ],\n",
    "#     source_dir='preprocess',\n",
    "#     code='preprocess.py'\n",
    "#     # arguments=['--input-data', input_data],\n",
    "# )\n",
    "\n",
    "# step_process = ProcessingStep(\n",
    "#     name='nba-preprocess',\n",
    "#     step_args=processor_run_args,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9582d345-5ffb-4bf7-adc4-2ded23dfeefd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "s3_processing_path = 'nba/code/processing.py'\n",
    "s3_client.upload_file('code/preprocess.py', bucket, s3_processing_path)\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=sk_version,\n",
    "    role=sm_role,\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1,\n",
    "    base_job_name=f'nba-preprocess',\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name='nba-preprocess',\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination='/opt/ml/processing/input'),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='train', source='/opt/ml/processing/train', destination='s3://sagemaker-pipelines-hwm/nba/preprocess/train'),\n",
    "        # ProcessingOutput(output_name='val', source='/opt/ml/processing/val'),\n",
    "        ProcessingOutput(output_name='test', source='/opt/ml/processing/test', destination='s3://sagemaker-pipelines-hwm/nba/preprocess/test'),\n",
    "    ],\n",
    "    code='s3://{}/{}'.format(bucket, s3_processing_path)\n",
    ")\n",
    "\n",
    "# step_process.arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b847a8-6292-4efe-90fd-e614b0e7c416",
   "metadata": {},
   "source": [
    "#### **TRAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "46b0dc8e-f77d-42cd-9da7-9055190531db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/train.py    \n",
    "import argparse\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import subprocess\n",
    "import sys\n",
    "import tarfile\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta as td\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = 'sagemaker-pipelines-hwm'\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--epochs', type=int, default=1)\n",
    "    # parser.add_argument('--batch_size', type=int, default=64)\n",
    "    # parser.add_argument('--learning_rate', type=float, default=0.1)\n",
    "    parser.add_argument('--train', type=str, default='/opt/ml/processing/train/') \n",
    "    parser.add_argument('--test', type=str, default='/opt/ml/processing/test/')\n",
    "    parser.add_argument('--sm-model-dir', type=str, default='/opt/ml/processing/model/')\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "# class PrintDot(tf.keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         # if epoch == 0:\n",
    "#         print(str(epoch)+' ', end='')\n",
    "\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # if we use a processing step to train, install tensorflow first\n",
    "    install('tensorflow==2.9.2')\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    args, _ = parse_args()\n",
    "    \n",
    "    print('args are:', args)\n",
    "    \n",
    "    target = 'home_win'\n",
    "    \n",
    "    x_train = pd.read_csv(os.path.join(args.train, 'train.csv'))\n",
    "    x_test = pd.read_csv(os.path.join(args.test, 'test.csv'))\n",
    "    \n",
    "    y_train = x_train.pop(target)\n",
    "    y_test = x_test.pop(target)\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # y_train = np.load(os.path.join(args.train, 'y_train.npy'))\n",
    "    # y_val = np.load(os.path.join(args.val, 'y_val.npy'))\n",
    "    # y_test = np.load(os.path.join(args.test, 'y_test.npy'))\n",
    "    \n",
    "    # set random seed\n",
    "    tf.random.set_seed(16)\n",
    "\n",
    "    # create the model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        #tf.keras.layers.Dropout(0.1), \n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        #tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(4, activation='relu'),\n",
    "        #tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid') # output shape is 1\n",
    "    ])\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # fit the model\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=args.epochs,\n",
    "        validation_data=(x_test, y_test)\n",
    "    ) # see how the model performs on the test set during training\n",
    "\n",
    "    model_assets = {\n",
    "        'model': model,\n",
    "        'history': pd.DataFrame.from_dict(history.history),\n",
    "        'name': 'model_'+str(int(datetime.datetime.now().timestamp()*100000))+'_'+str(history.history['val_accuracy'][-1])\n",
    "    }\n",
    "    \n",
    "    name = 'model'\n",
    "    tar_name = 'model.tar.gz'\n",
    "    local_path = args.sm_model_dir\n",
    "    model.save(os.path.join(local_path, name, '1'))\n",
    "    # tf.keras.models.save_model(model_assets['model'], os.path.join(path, name, '00001'))\n",
    "    tar = tarfile.open(os.path.join(local_path, tar_name), 'w:gz')\n",
    "    for file_name in glob.glob(os.path.join(local_path, name, '*')):\n",
    "        print('Adding %s...' % file_name)\n",
    "        tar.add(file_name, os.path.basename(file_name))\n",
    "    tar.close()\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree('/opt/ml/processing/model/model') \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # store model accuracy in a dict (JSON)\n",
    "    my_result = {'accuracy': history.history['val_accuracy'][-1]}\n",
    "    \n",
    "    # option 1) write JSON to S3 via buffer\n",
    "    output_buffer = StringIO()\n",
    "    output_buffer.write(json.dumps(my_result))\n",
    "    s3_resource.Object(bucket, 'nba/eval/accuracy.json').put(Body=output_buffer.getvalue())\n",
    "\n",
    "    # option 2) write JSON inside sagemaker session for use in next steps\n",
    "    output_dir = '/opt/ml/processing/evaluation'\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    evaluation_path = f'{output_dir}/evaluation.json'\n",
    "    with open(evaluation_path, 'w') as f:\n",
    "       f.write(json.dumps(my_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49626a66-2c86-4b7e-8046-5be00ca894bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "# where to store the trained model\n",
    "model_path = f's3://{bucket}/{prefix}/models/{current_time}/'\n",
    "\n",
    "s3_training_path = 'nba/code/train.py'\n",
    "s3_client.upload_file('code/train.py', bucket, s3_training_path)\n",
    "\n",
    "hyperparameters = {'epochs': training_epochs}\n",
    "tensorflow_version = tf_version\n",
    "python_version = python_version\n",
    "\n",
    "tf2_estimator = TensorFlow(\n",
    "    source_dir='code',\n",
    "    entry_point='train.py',\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1,\n",
    "    framework_version=tensorflow_version,\n",
    "    role=sm_role,\n",
    "    base_job_name='nba-train',\n",
    "    output_path=model_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    py_version=python_version\n",
    ")\n",
    "\n",
    "# # Use the tf2_estimator in a Sagemaker pipelines ProcessingStep.\n",
    "# # NOTE how the input to the training job directly references the output of the previous step.\n",
    "# step_train = TrainingStep(\n",
    "#     name='nba-train',\n",
    "#     estimator=tf2_estimator,\n",
    "#     inputs={\n",
    "#         'train': TrainingInput(\n",
    "#             s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "#                 'train'\n",
    "#             ].S3Output.S3Uri,\n",
    "#             content_type='text/csv',\n",
    "#         ),\n",
    "#         #'val': TrainingInput(\n",
    "#         #    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "#         #        'val'\n",
    "#         #    ].S3Output.S3Uri,\n",
    "#         #    content_type='text/csv',\n",
    "#         #),\n",
    "#         'test': TrainingInput(\n",
    "#             s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "#                 'test'\n",
    "#             ].S3Output.S3Uri,\n",
    "#             content_type='text/csv',\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "## Here we avoid using the built-in TrainingStep, instead customising a ProcessingStep to do the same task.\n",
    "## This allows more customisation of input and outplut locations for organizing S3 as we wish....\n",
    "step_train = ProcessingStep(\n",
    "    name='nba-train',\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/train',\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                'test'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/test',\n",
    "        ),\n",
    "        \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='model', source='/opt/ml/processing/model', destination='s3://sagemaker-pipelines-hwm/nba/models/{}'.format(current_time)),\n",
    "    ],\n",
    "    code='s3://{}/{}'.format(bucket, s3_training_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bbd30e-bf98-4d95-a9ae-dfee56ddf16b",
   "metadata": {},
   "source": [
    "#### **EVALUATE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f861a658-bc69-4983-8d0a-ec4afc681ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluate.py\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import tarfile\n",
    "import boto3\n",
    "\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = 'sagemaker-pipelines-hwm'\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    install('tensorflow==2.9.2') # we can add any package similarly\n",
    "    \n",
    "    target = 'home_win'\n",
    "    \n",
    "    model_path = f'/opt/ml/processing/model/model.tar.gz'\n",
    "    with tarfile.open(model_path, 'r:gz') as tar:\n",
    "        tar.extractall('./model')\n",
    "    import tensorflow as tf\n",
    "\n",
    "    model = tf.keras.models.load_model('./model/1')\n",
    "    test_path = '/opt/ml/processing/test/'\n",
    "    x_test = pd.read_csv(os.path.join(test_path, 'test.csv'))\n",
    "    y_test = x_test.pop(target)\n",
    "    x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "    #y_test = np.load(os.path.join(test_path, 'y_test.npy'))\n",
    "    scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "    print('\\nTest Loss & Accuracy:', scores)\n",
    "\n",
    "    report_dict = {'accuracy': scores[1]}\n",
    "\n",
    "    output_dir = '/opt/ml/processing/evaluation'\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f'{output_dir}/accuracy_eval.json'\n",
    "    with open(evaluation_path, 'w') as f:\n",
    "        f.write(json.dumps(report_dict))\n",
    "        \n",
    "    output_buffer = StringIO()\n",
    "    output_buffer.write(json.dumps(report_dict))\n",
    "    s3_resource.Object(bucket, 'nba/eval/accuracy_eval.json').put(Body=output_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4b9a08d-090f-4c2e-8595-3907c0f68142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluate_model_processor = SKLearnProcessor(\n",
    "    framework_version='1.0-1',\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1,\n",
    "    base_job_name='nba-evaluate',\n",
    "    role=sm_role\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='accuracy_eval.json'\n",
    ")\n",
    "\n",
    "step_evaluate = ProcessingStep(\n",
    "    name='nba-evaluate',\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ProcessingOutputConfig.Outputs['model'].S3Output.S3Uri,\n",
    "            # step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination='/opt/ml/processing/model',\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                'test'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/test',\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='evaluation', source='/opt/ml/processing/evaluation'),\n",
    "    ],\n",
    "    code='code/evaluate.py',\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0239b-63c2-4d6f-8c73-930e3996c87b",
   "metadata": {},
   "source": [
    "#### **SEND PERFORMANCE EMAIL - GOOD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d3edf36-0876-4029-89fe-f140f5592ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_code = \"\"\"\n",
    "import json\n",
    "import boto3\n",
    "import pathlib\n",
    "\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.header import Header\n",
    "from email.utils import formataddr\n",
    "    \n",
    "s3_client = client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket = 'sagemaker-pipelines-hwm'\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    evaluation_s3_uri = 's3://sagemaker-pipelines-hwm/nba/eval/accuracy.json' # event['evaluation_s3_uri']\n",
    "    path_parts = evaluation_s3_uri.replace('s3://', '').split('/')\n",
    "    bucket = path_parts.pop(0)\n",
    "    key = '/'.join(path_parts)\n",
    "\n",
    "    content = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    text = content['Body'].read().decode()\n",
    "    evaluation_json = json.loads(text)\n",
    "    accuracy = evaluation_json['accuracy'] #['regression_metrics']['mse']['value']\n",
    "    \n",
    "    # email dispatch code\n",
    "    msg = MIMEMultipart('alternative')\n",
    "    msg['From'] = formataddr((str(Header('MyWebsite', 'utf-8')), params['my_email']))\n",
    "    msg['To'] = params['my_email']\n",
    "    msg['Subject'] = 'Great Accuracy! {}'.format(accuracy)\n",
    "    html = 'be proud of this great accuracy wooop!'\n",
    "    msg.attach(MIMEText(html, 'html'))\n",
    "    s = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "    s.ehlo()\n",
    "    s.login(params['my_email'], params['my_app_password'])\n",
    "    s.sendmail(params['my_email'], params['my_email'], msg.as_string())\n",
    "    s.quit()\n",
    "    \n",
    "    report_dict = {\n",
    "        'regression_metrics': {\n",
    "            'mse': {'value': 0.5, 'standard_deviation': 'NaN'},\n",
    "        },\n",
    "    }\n",
    "        \n",
    "    output_buffer = StringIO()\n",
    "    output_buffer.write(json.dumps(report_dict))\n",
    "    s3_resource.Object(bucket, 'nba/eval/accuracy_good.json').put(Body=output_buffer.getvalue())\n",
    "    \n",
    "    return {'statusCode': 200, 'body': json.dumps('E-Mail Sent Successfully')}\n",
    "\"\"\".replace(\"params['my_email']\", \"'\"+params['my_email']+\"'\").replace(\"params['my_app_password']\", \"'\"+params['my_app_password']+\"'\")\n",
    "\n",
    "with open('send_email_lambda.py', 'w') as f:\n",
    "    f.write(email_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72bb23d8-814d-4446-a957-69c21914ade8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/send_email_lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/send_email_lambda.py\n",
    "import json\n",
    "import boto3\n",
    "import pathlib\n",
    "\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.header import Header\n",
    "from email.utils import formataddr\n",
    "    \n",
    "s3_client = client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket = 'sagemaker-pipelines-hwm'\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    evaluation_s3_uri = 's3://sagemaker-pipelines-hwm/nba/eval/accuracy.json' # event['evaluation_s3_uri']\n",
    "    path_parts = evaluation_s3_uri.replace('s3://', '').split('/')\n",
    "    bucket = path_parts.pop(0)\n",
    "    key = '/'.join(path_parts)\n",
    "\n",
    "    content = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    text = content['Body'].read().decode()\n",
    "    evaluation_json = json.loads(text)\n",
    "    accuracy = evaluation_json['accuracy'] #['regression_metrics']['mse']['value']\n",
    "    \n",
    "    # email dispatch code\n",
    "    msg = MIMEMultipart('alternative')\n",
    "    msg['From'] = formataddr((str(Header('MyWebsite', 'utf-8')), params['my_email']))\n",
    "    msg['To'] = params['my_email']\n",
    "    msg['Subject'] = 'Great Accuracy! {}'.format(accuracy)\n",
    "    html = 'be proud of this great accuracy wooop!'\n",
    "    msg.attach(MIMEText(html, 'html'))\n",
    "    s = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "    s.ehlo()\n",
    "    s.login(params['my_email'], params['my_app_password'])\n",
    "    s.sendmail(params['my_email'], params['my_email'], msg.as_string())\n",
    "    s.quit()\n",
    "    \n",
    "    report_dict = {\n",
    "        'regression_metrics': {\n",
    "            'mse': {'value': 0.5, 'standard_deviation': 'NaN'},\n",
    "        },\n",
    "    }\n",
    "        \n",
    "    output_buffer = StringIO()\n",
    "    output_buffer.write(json.dumps(report_dict))\n",
    "    s3_resource.Object(bucket, 'nba/eval/accuracy_good.json').put(Body=output_buffer.getvalue())\n",
    "    \n",
    "    return {'statusCode': 200, 'body': json.dumps('E-Mail Sent Successfully')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6168b2df-62a0-4224-8d6d-12d204b94266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "evaluation_s3_uri = '{}/accuracy.json'.format(\n",
    "    's3://sagemaker-pipelines-hwm/nba/eval'\n",
    "    # step_evaluate.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    ")\n",
    "evaluation_s3_uri_raw = step_evaluate.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "\n",
    "send_email_lambda_function_good_name = 'sagemaker-lambda-email' #-' + current_time\n",
    "\n",
    "send_email_lambda_function_good = Lambda(\n",
    "    function_name=send_email_lambda_function_good_name,\n",
    "    execution_role_arn=lambda_role, # role,\n",
    "    script='send_email_lambda.py',\n",
    "    handler='send_email_lambda.lambda_handler'\n",
    ")\n",
    "\n",
    "send_email_good = LambdaStep(\n",
    "    name='send-email-good',\n",
    "    lambda_func=send_email_lambda_function_good,\n",
    "    inputs={\n",
    "        'evaluation_s3_uri': evaluation_s3_uri\n",
    "        #ProcessingInput(\n",
    "        #    source=step_evaluate.properties.ProcessingOutputConfig.Outputs[\n",
    "        #        'evaluation'\n",
    "        #    ].S3Output.S3Uri,\n",
    "        #    destination='/opt/ml/processing/eval',\n",
    "        #)\n",
    "        # 'evaluation_s3_uri_raw': evaluation_s3_uri_raw,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed649f0f-5652-47e8-89e3-c4c4f995a53c",
   "metadata": {},
   "source": [
    "#### **SEND PERFORMANCE EMAIL - BAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "673f423d-c815-415b-955d-a1f8650b0c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "email_code_bad = \"\"\"\n",
    "import json\n",
    "import boto3\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "s3_client = client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket = 'sagemaker-pipelines-hwm'\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    # print(f'Received Event: {event}')\n",
    "\n",
    "    evaluation_s3_uri = 's3://sagemaker-pipelines-hwm/nba/eval/accuracy.json' # event['evaluation_s3_uri']\n",
    "    path_parts = evaluation_s3_uri.replace('s3://', '').split('/')\n",
    "    bucket = path_parts.pop(0)\n",
    "    key = '/'.join(path_parts)\n",
    "\n",
    "    content = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    text = content['Body'].read().decode()\n",
    "    evaluation_json = json.loads(text)\n",
    "    mse = evaluation_json['accuracy'] #['regression_metrics']['mse']['value']\n",
    "\n",
    "    subject_line = 'Please check high MSE ({}) detected on model evaluation'.format(mse)\n",
    "    print(f'Sending E-Mail to Data Science Team with subject line: {subject_line}')\n",
    "    \n",
    "    report_dict = {\n",
    "        'regression_metrics': {\n",
    "            'mse': {'value': 0.5, 'standard_deviation': 'NaN'},\n",
    "        },\n",
    "    }\n",
    "        \n",
    "    output_buffer = StringIO()\n",
    "    output_buffer.write(json.dumps(report_dict))\n",
    "    s3_resource.Object(bucket, 'nba/eval/accuracy_bad.json').put(Body=output_buffer.getvalue())\n",
    "\n",
    "    \n",
    "    return {'statusCode': 200, 'body': json.dumps('E-Mail Sent Successfully')}\n",
    "\"\"\".replace(\"params['my_email']\", \"'\"+params['my_email']+\"'\").replace(\"params['my_app_password']\", \"'\"+params['my_app_password']+\"'\")\n",
    "\n",
    "with open('send_email_lambda_bad.py', 'w') as f:\n",
    "    f.write(email_code_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6fd882b1-fce9-4712-9a99-d153a445250a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "evaluation_s3_uri = '{}/accuracy.json'.format(\n",
    "    's3://sagemaker-pipelines-hwm/nba/eval'\n",
    "    # step_evaluate.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    ")\n",
    "evaluation_s3_uri_raw = step_evaluate.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "\n",
    "send_email_lambda_function_bad_name = 'sagemaker-send-email-to-ds-team-lambda-' + current_time\n",
    "\n",
    "send_email_lambda_function_bad = Lambda(\n",
    "    function_name=send_email_lambda_function_bad_name,\n",
    "    execution_role_arn=lambda_role, # role,\n",
    "    script='send_email_lambda_bad.py',\n",
    "    handler='send_email_lambda_bad.lambda_handler',\n",
    ")\n",
    "\n",
    "send_email_bad = LambdaStep(\n",
    "    name='send-email-bad',\n",
    "    lambda_func=send_email_lambda_function_bad,\n",
    "    inputs={\n",
    "        'evaluation_s3_uri': evaluation_s3_uri\n",
    "        #ProcessingInput(\n",
    "        #    source=step_evaluate.properties.ProcessingOutputConfig.Outputs[\n",
    "        #        'evaluation'\n",
    "        #    ].S3Output.S3Uri,\n",
    "        #    destination='/opt/ml/processing/eval',\n",
    "        #)\n",
    "        # 'evaluation_s3_uri_raw': evaluation_s3_uri_raw,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52634ce5-5bf4-4f71-9164-6680512fa31b",
   "metadata": {},
   "source": [
    "#### **REGISTER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6f53262-fe76-4a0d-8e6f-e5a4e55afa91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "# Create ModelMetrics object using the evaluation report from the evaluation step\n",
    "# A ModelMetrics object contains metrics captured from a model.\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=evaluation_s3_uri,\n",
    "        content_type='application/json',\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a RegisterModel step, which registers the model with Sagemaker Model Registry.\n",
    "step_register_model = RegisterModel(\n",
    "    name='register-model',\n",
    "    estimator=tf2_estimator,\n",
    "    model_data='s3://sagemaker-pipelines-hwm/nba/models/{}/model.tar.gz'.format(current_time),\n",
    "        # step_train.properties.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri,\n",
    "        # step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['text/csv'],\n",
    "    inference_instances=['ml.m5.large', 'ml.m5.xlarge'],\n",
    "    transform_instances=['ml.m5.xlarge'],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db23bc-c0f3-4e2c-a1a1-08ec9ddd8c10",
   "metadata": {},
   "source": [
    "#### **CREATE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "013e1035-f5f8-4489-adee-cb9d4536349d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.step_collections import CreateModelStep\n",
    "# from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "# model = TensorFlowModel(\n",
    "#     role=role,\n",
    "#     model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#     framework_version=tensorflow_version,\n",
    "#     sagemaker_session=sagemaker_session,\n",
    "# )\n",
    "\n",
    "# step_create_model = CreateModelStep(\n",
    "#     name='create-model',\n",
    "#     model=model,\n",
    "#     display_name='does-this-work',\n",
    "#     inputs=sagemaker.inputs.CreateModelInput(instance_type='ml.m5.large'),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8095b8b4-5fe1-4ce9-93f3-43f1f1882cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# import sagemaker\n",
    "    \n",
    "# def lambda_handler(event, context):\n",
    "    \n",
    "#     # role = sagemaker.get_execution_role()\n",
    "#     role = params['sm_role']\n",
    "#     container_def = {\n",
    "#         'Image': '763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-inference:2.9.2-cpu',\n",
    "#         'Environment': {},\n",
    "#         'ModelDataUrl': # 's3://....../model.tar.gz' (check this anbd make dynamic)\n",
    "#     }\n",
    "    \n",
    "#     boto3.client('sagemaker').create_model(ModelName='model-name-lambda-awesomeness4', ExecutionRoleArn=role, PrimaryContainer=container_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c456ded8-34d9-4f24-984c-6e17e60416ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/create_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/create_model.py\n",
    "import argparse\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--endpoint_instance_type', type=str)\n",
    "    parser.add_argument('--endpoint_config_name', type=str)\n",
    "    parser.add_argument('--endpoint_name', type=str)\n",
    "    parser.add_argument('--model_name', type=str)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    sm = boto3.client('sagemaker', region_name='us-west-2')\n",
    "\n",
    "    role = params['sm_role']\n",
    "    container_def = {\n",
    "        'Image': '763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-inference:2.9.2-cpu',\n",
    "        'Environment': {},\n",
    "        'ModelDataUrl': 's3:.....model.tar.gz' # (check and make dynamic)\n",
    "    }\n",
    "\n",
    "    sm.create_model(ModelName=args.model_name, ExecutionRoleArn=role, PrimaryContainer=container_def)\n",
    "\n",
    "    current_time = time.strftime('%m-%d-%H-%M-%S', time.localtime())\n",
    "    endpoint_instance_type = args.endpoint_instance_type\n",
    "    endpoint_config_name = args.endpoint_config_name\n",
    "    endpoint_name = args.endpoint_name\n",
    "    model_name = args.model_name\n",
    "\n",
    "    create_endpoint_config_response = sm.create_endpoint_config(\n",
    "        EndpointConfigName = endpoint_config_name,\n",
    "        ProductionVariants = [\n",
    "            {\n",
    "                'InstanceType': endpoint_instance_type,\n",
    "                'InitialVariantWeight': 1,\n",
    "                'InitialInstanceCount': 1,\n",
    "                'ModelName': model_name,\n",
    "                'VariantName': 'AllTraffic',\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    print(f'create_endpoint_config_response: {create_endpoint_config_response}')\n",
    "\n",
    "    list_endpoints_response = sm.list_endpoints(\n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending',\n",
    "        NameContains=endpoint_name,\n",
    "    )\n",
    "    print(f'list_endpoints_response: {list_endpoints_response}')\n",
    "\n",
    "    if len(list_endpoints_response['Endpoints']) > 0:\n",
    "        print('Updating Endpoint with new Endpoint Configuration')\n",
    "        update_endpoint_response = sm.update_endpoint(\n",
    "            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "        )\n",
    "        print(f'update_endpoint_response: {update_endpoint_response}')\n",
    "    else:\n",
    "        print('Creating Endpoint')\n",
    "        create_endpoint_response = sm.create_endpoint(\n",
    "            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "        )\n",
    "        print(f'create_endpoint_response: {create_endpoint_response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55b5088c-22ce-4eac-ace4-e7c158425801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_sagemaker_model_processor = SKLearnProcessor(\n",
    "    framework_version=sk_version,\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1,\n",
    "    base_job_name='nba-create-sagemaker-model',\n",
    "    role=sm_role\n",
    ")\n",
    "\n",
    "model_name = 'model-name-lambda-awesomeness-100'\n",
    "endpoint_config_name = 'nba-pipeline-model-config'\n",
    "endpoint_name = 'nba-pipeline-model-endpoint'\n",
    "\n",
    "# Use the evaluate_model_processor in a Sagemaker pipelines ProcessingStep.\n",
    "step_create_model = ProcessingStep(\n",
    "    name='nba-create-sagemaker-model',\n",
    "    processor=create_sagemaker_model_processor,\n",
    "    \n",
    "    ProcessingInput(\n",
    "        source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "            'train'\n",
    "        ].S3Output.S3Uri,\n",
    "        destination='/opt/ml/processing/train',\n",
    "    )\n",
    "    #    ProcessingInput(\n",
    "    #        source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    #        destination='/opt/ml/processing/model',\n",
    "    #    )\n",
    "    #     ProcessingInput(\n",
    "    #         source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "    #             'test'\n",
    "    #         ].S3Output.S3Uri,\n",
    "    #         destination='/opt/ml/processing/test',\n",
    "    #     ),\n",
    "    # ],\n",
    "    \n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='create_output', source='/opt/ml/processing/train'),\n",
    "    ],\n",
    "    \n",
    "    job_arguments = [\n",
    "        '--model_name', model_name,\n",
    "        '--endpoint_name', endpoint_name,\n",
    "        '--endpoint_config_name', endpoint_config_name,\n",
    "        '--endpoint_instance_type', endpoint_instance_type\n",
    "    ], \n",
    "    \n",
    "    code='code/create_model.py'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121ddb1-2492-474b-a17d-e183897f79bd",
   "metadata": {},
   "source": [
    "#### **DEPLOY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bbf0070-be94-4d30-ac96-248d2f6204b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/deploy_model_lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/deploy_model_lambda.py\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "def main(event, context):\n",
    "\n",
    "    print(f'Received Event: {event}')\n",
    "\n",
    "    current_time = time.strftime('%m-%d-%H-%M-%S', time.localtime())\n",
    "    endpoint_instance_type = event['endpoint_instance_type']\n",
    "    model_name = event['model_name']\n",
    "    endpoint_config_name = '{}-{}'.format(event['endpoint_config_name'], current_time)\n",
    "    endpoint_name = event['endpoint_name']\n",
    "\n",
    "    # Create Endpoint Configuration\n",
    "    create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                'InstanceType': endpoint_instance_type,\n",
    "                'InitialVariantWeight': 1,\n",
    "                'InitialInstanceCount': 1,\n",
    "                'ModelName': model_name,\n",
    "                'VariantName': 'AllTraffic',\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    print(f'create_endpoint_config_response: {create_endpoint_config_response}')\n",
    "\n",
    "    # Check if an endpoint exists. If no - Create new endpoint, if yes - Update existing endpoint\n",
    "    list_endpoints_response = sm_client.list_endpoints(\n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending',\n",
    "        NameContains=endpoint_name,\n",
    "    )\n",
    "    print(f'list_endpoints_response: {list_endpoints_response}')\n",
    "\n",
    "    if len(list_endpoints_response['Endpoints']) > 0:\n",
    "        print('Updating Endpoint with new Endpoint Configuration')\n",
    "        update_endpoint_response = sm_client.update_endpoint(\n",
    "            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "        )\n",
    "        print(f'update_endpoint_response: {update_endpoint_response}')\n",
    "    else:\n",
    "        print('Creating Endpoint')\n",
    "        create_endpoint_response = sm_client.create_endpoint(\n",
    "            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "        )\n",
    "        print(f'create_endpoint_response: {create_endpoint_response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa2bab38-07c7-436c-b444-0afe0307065e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "endpoint_config_name = 'nba-pipeline-model-config'\n",
    "endpoint_name = 'nba-pipeline-model-endpoint'\n",
    "\n",
    "deploy_model_lambda_function_name = 'sagemaker-deploy-model'\n",
    "\n",
    "deploy_model_lambda_function = Lambda(\n",
    "    function_name=deploy_model_lambda_function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script='code/deploy_model_lambda.py',\n",
    "    handler='deploy_model_lambda.main',\n",
    ")\n",
    "\n",
    "step_deploy_model = LambdaStep(\n",
    "    name='nba-deploy-model',\n",
    "    lambda_func=deploy_model_lambda_function,\n",
    "    inputs={\n",
    "        'model_name': step_create_model.arguments['AppSpecification']['ContainerArguments'][1],\n",
    "        'endpoint_config_name': endpoint_config_name,\n",
    "        'endpoint_name': endpoint_name,\n",
    "        'endpoint_instance_type': endpoint_instance_type,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b24f1-7370-4339-98f6-249145eea36b",
   "metadata": {},
   "source": [
    "#### **CONDITIONAL EXECUTION BASED ON MODEL ACCURACY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b47e0918-03c6-4a5a-8183-feb395e7f264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo, ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# Create accuracy condition to ensure the model meets performance requirements.\n",
    "# Models with a test accuracy lower than the condition will not be registered with the model registry.\n",
    "cond_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_evaluate.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path='accuracy',\n",
    "    ),\n",
    "    right=accuracy_threshold,\n",
    ")\n",
    "\n",
    "# Create a Sagemaker Pipelines ConditionStep, using the condition above.\n",
    "# Enter the steps to perform if the condition returns True / False.\n",
    "step_cond = ConditionStep(\n",
    "    name='accuracy-above-threshold-condition',\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[send_email_good, step_register_model], # step_deploy_model], #, step_create_model\n",
    "    else_steps=[send_email_bad],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b0377-2828-4950-9d0b-8c96c5dd41b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36956c04-4b1a-4b09-b8aa-bd0808f265d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b380eb-8b79-419e-9693-54ac3599fbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cfd6be-8f18-41e9-b985-7eedb6829cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30226c4-6fd2-462a-aeec-a8c7d19f4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_s3(file_path, myfile, bucket='hwm-nba', dedupe_cols=None, sort=None, compression='zip'):\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    if type(myfile) == pd.core.frame.DataFrame:\n",
    "        if dedupe_cols is not None:\n",
    "            myfile = myfile.drop_duplicates(subset=dedupe_cols, keep='first')\n",
    "        if sort is not None:\n",
    "            myfile = myfile.sort_values(by=sort, ascending=True)\n",
    "        output_buffer = BytesIO() if compression == 'zip' else StringIO()\n",
    "        if compression == 'zip': file_path = '.'.join(file_path.split('.')[:-1])+'.zip'\n",
    "        myfile.to_csv(output_buffer, index=False, compression={'method':compression, 'archive_name':file_name})\n",
    "        myfile = output_buffer\n",
    "    s3_resource.Object(bucket, file_path).put(Body=myfile.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c54a1742-04a1-4c97-9c86-6004b00d0d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cba4581b-fe2d-4ecc-842d-9dfff7c30c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0c67f-6f94-4ca0-9220-d29429cda8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a49ca-9315-46ce-9221-ffb56622e9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c683c7-a398-4f85-9702-6e8b3a6c154c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437aa73d-8735-4215-8068-e8886f579a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf63ddc-c6b2-462f-a592-d2b5279bf092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb68e20e-7f9f-43db-90f8-a3cf411efc8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **ACTIVATE PIPELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aff317cb-1ca6-4421-8029-2128bb40392f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "current_time = time.strftime('%m-%d-%H-%M-%S', time.localtime())\n",
    "pipeline_name = 'nba-pipeline-1'\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        training_epochs,\n",
    "        accuracy_threshold,\n",
    "        endpoint_instance_type\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_evaluate, step_cond] # send_email] #step_register_model, #step_create_model] # \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6f5747a-9772-4f9b-a086-338c2f36558f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-pipelines-hwm/nba/raw'},\n",
       "  {'Name': 'TrainingEpochs', 'Type': 'String', 'DefaultValue': '10'},\n",
       "  {'Name': 'AccuracyThreshold', 'Type': 'Float', 'DefaultValue': 0.6},\n",
       "  {'Name': 'EndpointInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.large'}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'nba-preprocess',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.large',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/processing.py']},\n",
       "    'RoleArn': 'arn:aws:iam::668209712187:role/service-role/AmazonSageMaker-ExecutionRole-20220410T165348',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-pipelines-hwm/nba/code/processing.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-pipelines-hwm/nba/preprocess/train',\n",
       "        'LocalPath': '/opt/ml/processing/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-pipelines-hwm/nba/preprocess/test',\n",
       "        'LocalPath': '/opt/ml/processing/test',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'nba-train',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.large',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/train.py']},\n",
       "    'RoleArn': 'arn:aws:iam::668209712187:role/service-role/AmazonSageMaker-ExecutionRole-20220410T165348',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.nba-preprocess.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/train',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.nba-preprocess.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-pipelines-hwm/nba/code/train.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'model',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-pipelines-hwm/nba/models/03-13-11-56-10',\n",
       "        'LocalPath': '/opt/ml/processing/model',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'nba-evaluate',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.large',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/evaluate.py']},\n",
       "    'RoleArn': 'arn:aws:iam::668209712187:role/service-role/AmazonSageMaker-ExecutionRole-20220410T165348',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.nba-train.ProcessingOutputConfig.Outputs['model'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.nba-preprocess.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-668209712187/nba-evaluate-42197bfb9ddab24639737d17b358a347/input/code/evaluate.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-668209712187/nba-evaluate-42197bfb9ddab24639737d17b358a347/output/evaluation',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'accuracy_eval.json'}]},\n",
       "  {'Name': 'accuracy-above-threshold-condition',\n",
       "   'Type': 'Condition',\n",
       "   'Arguments': {'Conditions': [{'Type': 'GreaterThanOrEqualTo',\n",
       "      'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.nba-evaluate.PropertyFiles.EvaluationReport'},\n",
       "        'Path': 'accuracy'}},\n",
       "      'RightValue': {'Get': 'Parameters.AccuracyThreshold'}}],\n",
       "    'IfSteps': [{'Name': 'send-email-good',\n",
       "      'Type': 'Lambda',\n",
       "      'Arguments': {'evaluation_s3_uri': 's3://sagemaker-pipelines-hwm/nba/eval/accuracy.json'},\n",
       "      'FunctionArn': 'arn:aws:lambda:us-west-2:668209712187:function:sagemaker-lambda-email',\n",
       "      'OutputParameters': []},\n",
       "     {'Name': 'register-model-RegisterModel',\n",
       "      'Type': 'RegisterModel',\n",
       "      'Arguments': {'ModelPackageGroupName': 'nba-models-2023',\n",
       "       'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "          'S3Uri': 's3://sagemaker-pipelines-hwm/nba/eval/accuracy.json'}},\n",
       "        'Bias': {},\n",
       "        'Explainability': {}},\n",
       "       'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-inference:2.9.2-cpu',\n",
       "          'ModelDataUrl': 's3://sagemaker-pipelines-hwm/nba/models/03-13-11-56-10/model.tar.gz'}],\n",
       "        'SupportedContentTypes': ['text/csv'],\n",
       "        'SupportedResponseMIMETypes': ['text/csv'],\n",
       "        'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.large',\n",
       "         'ml.m5.xlarge'],\n",
       "        'SupportedTransformInstanceTypes': ['ml.m5.xlarge']},\n",
       "       'ModelApprovalStatus': 'PendingManualApproval'}}],\n",
       "    'ElseSteps': [{'Name': 'send-email-bad',\n",
       "      'Type': 'Lambda',\n",
       "      'Arguments': {'evaluation_s3_uri': 's3://sagemaker-pipelines-hwm/nba/eval/accuracy.json'},\n",
       "      'FunctionArn': 'arn:aws:lambda:us-west-2:668209712187:function:sagemaker-send-email-to-ds-team-lambda-03-13-11-56-10',\n",
       "      'OutputParameters': []}]}}]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f399946-8df8-4317-909a-2e1ff8064613",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-west-2:668209712187:pipeline/nba-pipeline-1',\n",
       " 'ResponseMetadata': {'RequestId': 'f5ea4ed0-a82a-423c-be5a-c348a811e298',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f5ea4ed0-a82a-423c-be5a-c348a811e298',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '82',\n",
       "   'date': 'Mon, 13 Mar 2023 11:25:47 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1bcce774-5675-415f-a45a-9f7bb0b57bd4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:us-west-2:668209712187:pipeline/nba-pipeline-1/execution/8luyen4fginm', sagemaker_session=<sagemaker.session.Session object at 0x282f3ad30>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.start() # can add parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5478753f-1c66-4f56-8376-2f90c3308cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13ed2b-74be-4187-a049-c500899df716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e301ed7-1d77-430e-9108-9e806f6d7496",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nba-pipeline-2 pipeline deleted\n",
      "nba-pipeline-1 pipeline deleted\n"
     ]
    }
   ],
   "source": [
    "def delete_sagemaker_pipeline(sm_client, pipeline_name):\n",
    "    try:\n",
    "        sm_client.delete_pipeline(\n",
    "            PipelineName=pipeline_name,\n",
    "        )\n",
    "        print(\"{} pipeline deleted\".format(pipeline_name))\n",
    "    except Exception as e:\n",
    "        print(\"{} \\n\".format(e))\n",
    "        return\n",
    "\n",
    "pipelines = sm.list_pipelines()\n",
    "pipeline_names = [ps['PipelineName'] for ps in pipelines['PipelineSummaries']]\n",
    "for p in pipeline_names:\n",
    "    try:\n",
    "        delete_sagemaker_pipeline(sm, p)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f049d4-4109-4849-a544-5811c547297e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8263b-a25c-42a7-9dec-ca03a681dccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "881a8189-cff2-427b-ba14-e4a2bb0cb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.delete_model_package_group(\n",
    "    ModelPackageGroupName='PipelineModelPackageGroup'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7507afb-ba29-4489-bbce-4d557c895dfb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupSummaryList': [{'ModelPackageGroupName': 'nba-models-2023',\n",
       "   'ModelPackageGroupArn': 'arn:aws:sagemaker:us-west-2:668209712187:model-package-group/nba-models-2023',\n",
       "   'CreationTime': datetime.datetime(2023, 3, 9, 17, 20, 52, 518000, tzinfo=tzlocal()),\n",
       "   'ModelPackageGroupStatus': 'Completed'},\n",
       "  {'ModelPackageGroupName': 'PipelineModelPackageGroup',\n",
       "   'ModelPackageGroupArn': 'arn:aws:sagemaker:us-west-2:668209712187:model-package-group/pipelinemodelpackagegroup',\n",
       "   'CreationTime': datetime.datetime(2023, 3, 2, 14, 36, 25, 649000, tzinfo=tzlocal()),\n",
       "   'ModelPackageGroupStatus': 'Completed'}],\n",
       " 'ResponseMetadata': {'RequestId': 'c054ef68-99b5-4d24-9f70-2c7a0474d956',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c054ef68-99b5-4d24-9f70-2c7a0474d956',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '486',\n",
       "   'date': 'Mon, 13 Mar 2023 11:53:03 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.list_model_package_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "28bef302-0b51-4471-b354-b16dff650d62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageSummaryList': [{'ModelPackageGroupName': 'PipelineModelPackageGroup',\n",
       "   'ModelPackageVersion': 1,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-west-2:668209712187:model-package/pipelinemodelpackagegroup/1',\n",
       "   'CreationTime': datetime.datetime(2023, 3, 2, 14, 36, 25, 960000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'Approved'}],\n",
       " 'ResponseMetadata': {'RequestId': '853bbf8f-f3ec-4df3-8488-0ced3aac5e3b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '853bbf8f-f3ec-4df3-8488-0ced3aac5e3b',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '307',\n",
       "   'date': 'Mon, 13 Mar 2023 11:54:47 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.list_model_packages(ModelPackageGroupName='PipelineModelPackageGroup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4795c3f8-085c-4227-845e-54855f063562",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.delete_model_package(\n",
    "    ModelPackageName='arn:aws:sagemaker:us-west-2:668209712187:model-package/pipelinemodelpackagegroup/1'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 tf1",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
